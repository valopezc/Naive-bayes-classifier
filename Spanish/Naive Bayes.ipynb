{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67f9b82",
   "metadata": {},
   "source": [
    "<a type=\"anchor\"></a>\n",
    "# **Proyecto MAC**\n",
    "# **Clasificador con redes bayesianas**\n",
    "Alumno: Victor Alberto Lopez Cardona\n",
    "\n",
    "Exp: 747175"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f6b93",
   "metadata": {},
   "source": [
    "<a type=\"anchor\" id=\"100\"></a>\n",
    "# **Contenido**\n",
    "\n",
    "1.\t[Introduccion](#1)\n",
    "2.\t[Requerimientos](#2)\n",
    "3.\t[Datos](#3)\n",
    "4.\t[Limpiar la informacion](#4)\n",
    "5.\t[Transformar la informacion en vectores](#5)\n",
    "6.\t[Entrenar el modelo](#6)\n",
    "7.\t[Pruebas](#7)\n",
    "8.\t[Conclusiones](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cadfe",
   "metadata": {},
   "source": [
    "# **1. Introduccion** <a type=\"anchor\" id=\"1\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adb36f",
   "metadata": {},
   "source": [
    "## **Multinomial Naïve Bayes algorithm**\n",
    "\n",
    "Con un modelo Multinomial Naïve Bayes, las muestras (vectores de características) representan las frecuencias con las que ciertos eventos han sido generados por un multinomial.(p1, . . . ,pn) \n",
    "donde pi es la probabilidad de que ocurra el evento i. Se prefiere usar el algoritmo Naïve Bayes multinomial en datos que se distribuyen multinomialmente. Es uno de los algoritmos estándar que se utiliza en la tipificación de categorización de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3660a",
   "metadata": {},
   "source": [
    "## **Gaussian Naïve Bayes algorithm**\n",
    "\n",
    "\n",
    "Cuando tenemos valores de atributos continuos, asumimos que los valores asociados con cada tipo se distribuyen de acuerdo con la distribución gaussiana o normal. Por ejemplo, suponga que los datos de entrenamiento contienen un atributo continuo x. Primero segmentamos los datos por tipo y luego calculamos la media y la varianza de x en cada tipo. Sea µi la media de los valores y sea σi la varianza de los valores asociados con el i-ésimo tipo. Supongamos que tenemos algún valor de observación xi. Entonces, la distribución de probabilidad de xi dado un tipo se puede calcular mediante la siguiente ecuación:\n",
    "\n",
    "\n",
    "![Gaussian Naive Bayes algorithm](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQEWCcq1XtC1Yw20KWSHn2axYa7eY-a0T1TGtdVn5PvOpv9wW3FeA&s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac67350e",
   "metadata": {},
   "source": [
    "## **Bernoulli Naïve Bayes algorithm**\n",
    "\n",
    "En el modelo de eventos multivariado de Bernoulli, las características son variables booleanas independientes (variables binarias) que describen entradas. Al igual que el modelo multinomial, este modelo también es popular para tareas de tipificación de documentos en las que se utilizan características de aparición de términos binarios en lugar de frecuencias de términos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9cc67b",
   "metadata": {},
   "source": [
    "Para nuestro proyecto utlizaremos Multinomial Naive Bayes algorithm porque utlizamos la cantidad de veces que se repite una palabra en los mensajes como indicador de si un mensaje es SPAM o no, el algoritmo multinomial de bayes toma en cuenta clasificacion multi clase, por lo tanto funciona con muchos atributos, representaremos nuestro documento con un vector que contenga los atributos cuyo valor es la frecuencia de una palabra en el documento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2856472",
   "metadata": {},
   "source": [
    "# **2. Requerimientos** <a type=\"anchor\" id=\"2\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea31bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43efc3",
   "metadata": {},
   "source": [
    "# **3. Datos** <a type=\"anchor\" id=\"3\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b561607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('Spam_data',sep='\\t',names=[\"type\",\"message\"])\n",
    "all_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b23dcd",
   "metadata": {},
   "source": [
    "Posibles indicadores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38c4fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     message                                                               \n",
       "       count unique                                                top freq\n",
       "type                                                                       \n",
       "ham     4825   4516                             Sorry, I'll call later   30\n",
       "spam     747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.groupby('type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f46f944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.490309\n",
       "std        59.944527\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['length']=all_data['message'].apply(len)\n",
    "all_data.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65629aee",
   "metadata": {},
   "source": [
    "El mensaje mas largo consta de 910 caracteres, entonces...\n",
    "\n",
    "La longitud del texto es un indicativo de si el mensaje es spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876ca2d",
   "metadata": {},
   "source": [
    "Ahora vamos a limpiar nuestra informacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e2a51",
   "metadata": {},
   "source": [
    "# **4. Limpiar la informacion** <a type=\"anchor\" id=\"4\"></a>\n",
    "[Contenido](#100)\n",
    "\n",
    "\n",
    "Para calcular todas las psoibilidades necesitamos tener un buen data frame, por lo que vamos a limpiar la informacion, vamos a remover las palabras que no nos aportan informacion y que mas se repiten, como \"the\", \"a\", \"is\"; La siguiente funcion se encarga de quitar esas palabras para todo el data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47830b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.corpus.stopwords.words('english')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "#remover letras que apocan poca info\n",
    "def clean_data(mnsj):\n",
    "    msg = [x for x in mnsj if x not in string.punctuation]\n",
    "    msg = ''.join(msg)\n",
    "    clean_msg = [x for x in msg.split() if x.lower not in nltk.corpus.stopwords.words('english')]\n",
    "    return clean_msg\n",
    "\n",
    "#all_data['message'].apply(clean_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549b301",
   "metadata": {},
   "source": [
    "# **5. Transformar la informacion en vectores** <a type=\"anchor\" id=\"5\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6156cfc",
   "metadata": {},
   "source": [
    "Actualmente tenemos un data frame con listas que contienen el mensaje, para poder vectorizar la informacion, vamos a hacer uso de la libreria sklearn y usaremos la funcion countvectorizer para obtener una matriz de tokens donde podremos ver cuantas veces se repite una palabra en cada mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c81442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 11747)\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer(analyzer=clean_data).fit(all_data['message'])\n",
    "df_vector = vector.transform(all_data['message'])\n",
    "frecuencias=TfidfTransformer().fit(df_vector)\n",
    "frecuencias_data_frame=frecuencias.transform(df_vector)\n",
    "print(frecuencias_data_frame.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898afec",
   "metadata": {},
   "source": [
    "# **6. Entrenar el modelo** <a type=\"anchor\" id=\"6\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e24f3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MultinomialNB().fit(frecuencias_data_frame,all_data['type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afb5e1",
   "metadata": {},
   "source": [
    "# **7. Pruebas** <a type=\"anchor\" id=\"7\"></a>\n",
    "[Contenido](#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4863e57",
   "metadata": {},
   "source": [
    "Vamos a probar con todo nuestro data frame ya vectorizado, y el modelo entrenado nos va a clasificar los mensajes, el modelo nos va a regresar una lista con los valores clasificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c5a4c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "resultados = modelo.predict(frecuencias_data_frame)\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "028ff2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... ha sido detectado como seguro\n",
      "El mensaje Ok lar... Joking wif u oni... ha sido detectado como seguro\n",
      "El mensaje Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's ha sido detectado como SPAM\n",
      "El mensaje U dun say so early hor... U c already then say... ha sido detectado como seguro\n",
      "El mensaje Nah I don't think he goes to usf, he lives around here though ha sido detectado como seguro\n",
      "El mensaje FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv ha sido detectado como seguro\n",
      "El mensaje Even my brother is not like to speak with me. They treat me like aids patent. ha sido detectado como seguro\n",
      "El mensaje As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune ha sido detectado como seguro\n",
      "El mensaje WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only. ha sido detectado como SPAM\n",
      "El mensaje Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030 ha sido detectado como SPAM\n",
      "El mensaje I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today. ha sido detectado como seguro\n",
      "El mensaje SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info ha sido detectado como SPAM\n",
      "El mensaje URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18 ha sido detectado como SPAM\n",
      "El mensaje I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times. ha sido detectado como seguro\n",
      "El mensaje I HAVE A DATE ON SUNDAY WITH WILL!! ha sido detectado como seguro\n",
      "El mensaje XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL ha sido detectado como seguro\n",
      "El mensaje Oh k...i'm watching here:) ha sido detectado como seguro\n",
      "El mensaje Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet. ha sido detectado como seguro\n",
      "El mensaje Fine if thats the way u feel. Thats the way its gota b ha sido detectado como seguro\n",
      "El mensaje England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+ ha sido detectado como SPAM\n",
      "El mensaje Is that seriously how you spell his name? ha sido detectado como seguro\n",
      "El mensaje I‘m going to try for 2 months ha ha only joking ha sido detectado como seguro\n",
      "El mensaje So ü pay first lar... Then when is da stock comin... ha sido detectado como seguro\n",
      "El mensaje Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already? ha sido detectado como seguro\n",
      "El mensaje Ffffffffff. Alright no way I can meet up with you sooner? ha sido detectado como seguro\n",
      "El mensaje Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol ha sido detectado como seguro\n",
      "El mensaje Lol your always so convincing. ha sido detectado como seguro\n",
      "El mensaje Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ? ha sido detectado como seguro\n",
      "El mensaje I'm back &amp; we're packing the car now, I'll let you know if there's room ha sido detectado como seguro\n",
      "El mensaje Ahhh. Work. I vaguely remember that! What does it feel like? Lol ha sido detectado como seguro\n",
      "El mensaje Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us ha sido detectado como seguro\n",
      "El mensaje Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You?  ha sido detectado como seguro\n",
      "El mensaje K tell me anything about you. ha sido detectado como seguro\n",
      "El mensaje For fear of fainting with the of all that housework you just did? Quick have a cuppa ha sido detectado como seguro\n",
      "El mensaje Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged ha sido detectado como seguro\n",
      "El mensaje Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am ha sido detectado como seguro\n",
      "El mensaje Oops, I'll let you know when my roommate's done ha sido detectado como seguro\n",
      "El mensaje I see the letter B on my car ha sido detectado como seguro\n",
      "El mensaje Anything lor... U decide... ha sido detectado como seguro\n",
      "El mensaje Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything! ha sido detectado como seguro\n",
      "El mensaje Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola ha sido detectado como seguro\n",
      "El mensaje Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy ha sido detectado como seguro\n",
      "El mensaje 07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow ha sido detectado como SPAM\n",
      "El mensaje WHO ARE YOU SEEING? ha sido detectado como seguro\n",
      "El mensaje Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches... ha sido detectado como seguro\n",
      "El mensaje No calls..messages..missed calls ha sido detectado como seguro\n",
      "El mensaje Didn't you get hep b immunisation in nigeria. ha sido detectado como seguro\n",
      "El mensaje Fair enough, anything going on? ha sido detectado como seguro\n",
      "El mensaje Yeah hopefully, if tyler can't do it I could maybe ask around a bit ha sido detectado como seguro\n",
      "El mensaje U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers. ha sido detectado como seguro\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,50):\n",
    "    if resultados[i] == \"ham\":\n",
    "        print(f\"El mensaje {all_data['message'][i]} ha sido detectado como seguro\")\n",
    "    elif resultados[i] == \"spam\":\n",
    "        print(f\"El mensaje {all_data['message'][i]} ha sido detectado como SPAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6b15e",
   "metadata": {},
   "source": [
    "Checar la precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1934fc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 97.21823402727925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "puntaje = accuracy_score(all_data['type'], resultados)\n",
    "print(f'Precision: {puntaje*100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5e9aa",
   "metadata": {},
   "source": [
    "# **8. Conclusiones** <a type=\"anchor\" id=\"8\"></a>\n",
    "[Contenido](#100)\n",
    "\n",
    "El objetivo del proyecto es hacer uso de redes bayesianas ingenuas para clasificar un mensaje como SPAM o como mensaje seguro, para hacer esto podemos hacer uso de 3 distintos algoritmos, que son el Multinomial, Gaussiano, y de Bernoulli, para este proyecto se opto por utilizar el algoritmo multinomial ya que para nuestro set de información que es un texto, este algoritmo funciona mejor.\n",
    "\n",
    "El proyecto logra clasificar los mensajes como SPAM o mensaje seguro con un 97% de precisión aproximadamente.\n",
    "Como áreas de mejora o trabajo futuro, podemos normalizar la información que tenemos, hay algunos mensajes que contienen una palabra mal escrita y podemos detectar esta palabra y corregirla para tener una tabla de frecuencias correcta en nuestro proyecto, esto nos llevara a un modelo de predicción mas preciso.\n",
    "\n",
    "En el código podemos observar que tenemos una función clean_data(), en esta función estamos eliminando palabras que no nos aportan información valiosa al mensaje, por lo que las eliminamos por cada uno de los mensajes que tenemos, esto mejoro la precisión de nuestro modelo en un 30%, ya que la mayoría de las palabras que se repetían en los mensajes eran “the”, “a”, is“, y el modelo identificaba erróneamente los mensajes que contenían SPAM.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "361e2ddaf2c6b03795ce05db07553fb246596910b41400f3d99eacd3e8da29ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
